plot(x = mpg$cty, y = mpg$hwy)
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point()
plot(x = mpg$cty, y = mpg$hwy)
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() +
coord_flip()
nz <- map_data("nz")
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_quickmap()
bar <- ggplot(data = diamonds) +
geom_bar(
mapping = aes(x = cut, fill = cut),
show.legend = FALSE,
width = 1
) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL)
bar + coord_flip()
bar + coord_polar()
bar + coord_flip()
bar
bar + coord_polar()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
c <- ggplot(mpg, aes(hwy))
c <- ggplot(mpg, aes(hwy))
c + geom_area(stat = "bin")
c + geom_area()
c + geom_area(stat = "bin")
c+ geom_density(kernel = "gaussian")
?geom_density
c + geom_density()
c + geom_density(alpha = .5
?geom_density
c + geom_density(alpha = .5)
c + geom_density()
c + geom_histogram()
c + geom_qq()
ggplot(mpg) + geom_qq(aes(hwy))
ggplot(mpg) + geom_qq(mapping = aes(x = hwy))
ggplot(mpg) + geom_qq(sample = hwy)
ggplot(data = mpg) + geom_qq(aes(sample = hwy))
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_bw()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_gray()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_dark()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_classic()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_minimal()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_void()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() + theme_minimal()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = drv),size = 3) +
geom_smooth(mapping = aes(linetype = drv),se = FALSE)
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = drv),size = 3) +
geom_smooth(mapping = aes(linetype = drv),se = FALSE)  + theme_minimal()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = drv),size = 3) +
geom_smooth(mapping = aes(linetype = drv),se = FALSE)  + theme_bw()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = drv),size = 3) +
geom_smooth(mapping = aes(linetype = drv),se = FALSE)  + theme_minimal()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = drv),size = 3) +
geom_smooth(mapping = aes(linetype = drv),se = FALSE)
install.packages("nycflights13")
library(nycflights13)
flights
filter(flights, month == 1, day == 1)
flights
filter(flights, month == 1, day == 1)
filter(flights, month == 1)
datasets::flights
?nycflights13
library(nycflights13)
?nycflights13
filter(flights, month == 1)
jan1 <- filter(flights, month == 1, day == 1)
jan1 <- filter(data = flights, month == 1, day == 1)
flights
jan1 <- filter(data = flights, month == 1, day == 1)
jan1 <- filter(flights, month == 1, day == 1)
flights <- copy_to(sc, flights, "flights")
select(flights, year:day, arr_delay, dep_delay)
library("tidyverse", lib.loc="~/R/win-library/3.3")
filter(flights, month == 1, day == 1)
jan1 <- filter(flights, month == 1, day == 1)
filter(flights, month == 11 | month == 12)
filter(flights, month == 11 | month == 12)
x <- data.frame(col1 = c(A,B,C,D), col2=c(2,3,4,3))
x <- data.frame(col1 = c('A','B','C','D'), col2=c(2,3,4,3))
x
filter(x, col1 == 'A')
filter(x, col1 == 'A',col1 == 'B')
filter(x, col1 == 'A' | col1 == 'B')
filter(x, col1 == 'A' & col1 == 'B')
filter(x, col1 == 'A' & col2 == 2)
df <- tibble(x = c(1, NA, 3))
df
filter(df, x > 1)
flights
filter(flights, arr_delay > 120)
filter(flights, dest == 'HOU' | dest == 'IAH')
distinct(flights,carrier)
filter(flights, carrier %in% 'UA','AA','DL')
filter(flights, carrier %in% c('UA','AA','DL'))
filter(flights, month %in% c(7,8,9))
filter(flights, sched_arr_time - arr_time > 120, arr_delay == 0)
filter(flights, sched_arr_time - arr_time > 120)
filter(flights, sched_arr_time - arr_time > 120, dep_delay <= 0)
filter(flights, dep_delay > 30, arr_delay <= 0)
filter(flights, dep_delay > 60, arr_delay <= 0)
60*6
filter(flights, dep_time > 0, dep_time < 360)
filter(flights, between(dep_time, 0,360))
filter(flights, dep_time >= 0, dep_time <= 360))
filter(flights, dep_time >= 0, dep_time <= 360)
filter(flights, between(dep_time, 0,360))
filter(flights, is.na(dep_time))
flights %>% filter(dep_time > 0, dep_time < 360)
filter(flights, dep_time > 0, dep_time < 360)
flights %>% filter(dep_time > 0, dep_time < 360)
flights_sml <- select(flights,
year:day,
ends_with("delay"),
distance,
air_time
)
mutate(flights_sml,
gain = arr_delay - dep_delay,
speed = distance / air_time * 60
)
rm(list = ls())
load("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/.RData")
data(mtcars)
dat <- subset(mtcars, select=c(mpg, am, vs))
ggplot(dat, aes(x=mpg, y=vs)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 14 - Logistic Regression")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
install.packages("class")
require(class)
training_set[1:2]
training_set[-3]
training_set[,-3]
training_set[3]
View(training_set)
View(dataset)
training_set[,3]
y_pred <- knn(train = training_set[,1:2],
test = test_set[,1:2],
cl = training_set[, 3],
k = 5
)
y_pred
View(test_set)
cm = table(test_set[, 3], y_pred)
cm
rm(... = ls())
rm(list = ls())
# KNR
# Importing the dataset
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting K-NN to the Training set and predicting the test set results
# install.packages("class")
require(class)
y_pred <- knn(train = training_set[,1:2],
test = test_set[,1:2],
cl = training_set[, 3],
k = 5
)
cm = table(test_set[, 3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = knn(train = training_set[,1:2],
test = grid_set,
cl = training_set[, 3],
k = 5
)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'K-NN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = knn(train = training_set[,1:2],
test = grid_set,
cl = training_set[, 3],
k = 5
)
y_grid = ifelse(prob_set > 0.5, 1, 0)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = knn(train = training_set[,1:2],
test = grid_set,
cl = training_set[, 3],
k = 5
)
plot(set[, -3],
main = 'K-NN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = knn(train = training_set[,1:2],
test = grid_set,
cl = training_set[, 3],
k = 5
)
plot(set[, -3],
main = 'K-NN (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 16 - Support Vector Machine (SVM)")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
library("e1071", lib.loc="~/R/win-library/3.3")
rm(list = ls())
# SVM - Support vector machines
# Importing the dataset
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 16 - Support Vector Machine (SVM)")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
require(e1071)
View(dataset)
classifier <- svm(formula = Purchased ~ . ,
data = training_set,
type = "C-classification",
kernel = "linear"
)
classifier
y_pred <- predict(object = classifier, newdata = test_set[,-3])
y_pred
View(test_set)
cm = table(test_set[, 3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'K-NN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("C:/Users/rahul/Desktop/accidents.csv")
setwd("C:/Users/rahul/Desktop/accidents.csv")
setwd("C:/Users/rahul/Desktop/")
dataset = read.csv('accidents.csv')
Accidents = read.csv('accidents.csv')
View(Accidents)
Accidents[1,]
mutate(.data = Accidents, toddler = X0.to.4 + X5.to.15)
require(tidyverse)
mutate(.data = Accidents, toddler = X0.to.4 + X5.to.15)
mutate(.data = Accidents, 0-15 = X0.to.4 + X5.to.15)
mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15)
Accidents = read.csv('accidents.csv')
mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15)
Accidents[1,]
Accidents = read.csv('accidents.csv')
require(tidyverse)
mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'16-20' = X30.to.39 + X40.to.49,
'16-20' = X50.to.59 + X60.to.69 + X70.and.over,
'16-20' = Unknown
)
Accidents = read.csv('accidents.csv')
mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'30-49' = X30.to.39 + X40.to.49,
'50+' = X50.to.59 + X60.to.69 + X70.and.over,
'Unknown' = Unknown
)
View(Accidents)
vis <- mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'30-49' = X30.to.39 + X40.to.49,
'50+' = X50.to.59 + X60.to.69 + X70.and.over,
'Unknown' = Unknown
)
vis
View(vis)
vis <- vis[,14:19]
vis <- vis[,14:18]
vis
Accidents = read.csv('accidents.csv')
vis <- mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'30-49' = X30.to.39 + X40.to.49,
'50+' = X50.to.59 + X60.to.69 + X70.and.over,
'Unknown' = Unknown
)
vis1 <- vis[,14:19]
vis1 <- vis[,14:18]
View(vis1)
View(vis)
Accidents[1,]
Accidents = read.csv('accidents.csv')
vis <- mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'30-49' = X30.to.39 + X40.to.49,
'50+' = X50.to.59 + X60.to.69 + X70.and.over,
'Unknown' = Unknown
)
View(vis)
vis1 <- vis[,14:18]
vis1
ggplot() +
geom_line(mapping = aes(x = vis$Date, y = vis$`0-15`))
ggplot() +
geom_line(mapping = aes(x = vis$Date, y = vis$`0-15`)) +
geom_line(mapping = aes(x = vis$Date, y = vis$`16-20`))
setwd("C:/Users/rahul/Google Drive/RMIT/Semester 2/Data Visualization/Week 1")
Accidents = read.csv('accidents.csv')
vis <- mutate(.data = Accidents, '0-15' = X0.to.4 + X5.to.15,
'16-20' = X16.to.17 + X18.to.20,
'21-29' = X21.to.25 + X26.to.29,
'30-49' = X30.to.39 + X40.to.49,
'50+' = X50.to.59 + X60.to.69 + X70.and.over,
'Unknown' = Unknown
)
ggplot() +
geom_line(mapping = aes(x = vis$Date, y = vis$`0-15`)) +
geom_line(mapping = aes(x = vis$Date, y = vis$`16-20`))
ggplot() +
geom_line(mapping = aes(x = vis$Date, y = vis$`0-15`)) +
geom_line(mapping = aes(x = vis$Date, y = vis$`16-20`))
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 17 - Kernel SVM")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
rm(list = ls())
setwd("C:/Users/rahul/Documents/UserData/Online Training/Machine Learning A-Z/Manual/Part 3 - Classification/Section 17 - Kernel SVM")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
View(dataset)
View(training_set)
View(test_set)
require(e1071)
classifier <- svm(formula = Purchased ~ . ,
data = training_set,
type = "C-classification",
kernel = "radial"
)
y_pred <- predict(object = classifier, newdata = test_set[,-3])
y_pred
cm = table(test_set[, 3], y_pred)
table(test_set[, 3], y_pred)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Kernel SVM (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Kernel SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
rm(list = ls())
